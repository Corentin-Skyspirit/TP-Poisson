# Compte rendu du TP Poisson

## Introduction

Le but de ce TD/TP √©tait de voir puis appliquer diff√©rents algorithmes pour r√©soudre un syst√®me lin√©aire issu de la discr√©tisation, par la m√©thode des diff√©rences finies, de l'√©quation de la chaleur 1D stationnaire. Les impl√©mentations sont r√©alis√©es en C avec BLAS et LAPACK.

# Travail pr√©liminaire

Nous avons effectu√©, avant toute impl√©mentation en C, un travail pr√©liminaire d'explications et de compr√©hension de l'√©quation de la chaleur.

Dans le cas o√π le terme source est nul $(ùëî=0)$, la solution analytique de l'√©quation est donn√©e par :
$$ ùëá(ùë•)= ùëá_0 + ùë•(ùëá_1 ‚àí ùëá_0) $$

## Exercice 1 

### Question 1



## Exercice 2

L'exercice 2, portant uniquement sur l'installation de BLAS/LAPACK ainsi que la cr√©ation du git et du makefile, nous ne nous attarderons pas dessus.

# M√©thode directe et stockage bande

## Exercice 3

### Question 1
Pour utiliser `BLAS` et `LAPACK`, nous devons d√©clarer et allouer les matrices sous forme d'**un tableau 1D contigu** (√©tant consid√©r√© comme un 2D).
Nous utiliserons pour cela `LAPACK_ROW_MAJOR` en C pour d√©clarer les tableaus en `Ligne-Major`.

Exemple:
```c++
double* A = (double*)malloc(m * n * sizeof(double));
```

### Question 2

La constante `LAPACK_COL_MAJOR` fait r√©f√©rence √† **l'ordre de stockage en m√©moire**.
Ici les matrices seront stock√©es en `Colonne-Major` c'est-√†-dire que les √©l√©ments sont stock√©s colonne par colonne. 
Le rangement en colonne-Major est plut√¥t utile pour d'autre langages (comme FORTRAN) car la C est lui en `Ligne-Major`.

### Question 3

La dimension principale (`ld`, ou `lda` pour leading dimension of A) permet d'indiquer comment une matrice est stock√©e en m√©moire.
Elle permet d'indiquer le **nombre d'√©l√©ments entre chaque ligne** (en colonne-major) ou chaque colonne (en ligne-major).

### Question 4

La fonction `dgbmv` est une fonction de la biblioth√®que `LAPACK` qui permet d'effectuer **une multiplication matrice-vecteur** pour une matrice bande.  

### Question 5

La fonction `dgbtrf` appartient √©galement √† la bilioth√®que LAPACK et effectue la **factorisation LU** d'une matrice bande avec **pivotement partiel**.

### Question 6

La fonction `dgbtrs` vient de LAPACK et **r√©sout un syst√®me d'√©quation lin√©aires** en utilisant la factorisation LU d'une matrice bande pr√©alablement calcul√©e par `dgbtrf`.
Cette fonction est optimale pour les matrices bandes car elle utilise leur structure particuli√®re pour limiter les calculs.

### Question 7

La fonction `dgbsv` effectue √† **la fois la factorisation LU et la r√©solution d'un syst√®me lin√©aire**.
Elle permet de combiner en une fonction `dgbtrf` et `dgbtrs` et est de fait tr√®s optimis√©e et utilisable pour les matirices bandes.

### Question 8

Soit R le r√©sidu : $R = b - A\^x$

L'erreur arri√®re est : 
$$\frac{||b - A\^x||}{||A||||\^x||}$$

L'erreur avant est : 
$$\frac{||k||}{||b||} = \frac{||b - A\^x||}{||b||} = \frac{||x - \^x||}{||x||}$$

Pour calculer la norme du vecteur : $n = sqrt(ddot(\&n, x, 1, x, 1))$

Pour calculer $||x - \^x||$ : $daxpy(\&n, x, 1, x, 1) = \^x-x = x$

et $nx = norme(x)$ avec $res = n / nx$

## Exercice 4

Lors de ce TP, nous avons choisi d'utiliser le stockage bande pour les matrices que nous allons utiliser. L'avantage du stockage bande est qu'il est utilisable sur BLAS/LAPACK et qu'il prend moins de place en m√©moire qu'une matrice compl√®te.

√âtant donn√© que nous avons des matrices tridiagonales, il est donc beaucoup plus optimis√© d'opter pour ce type de stockage de matrices.

Afin de valider les valeurs obtenues dans la matrice, il faut multiplier un **vecteur unitaire avec AB** avec la m√©thode `dgbmv`. Il faut ensuite v√©rifier que le r√©sultat correspond √† un **vecteur nul avec un 1 √† chaque extr√©mit√©s**.

## Exercice 5

Les performances de `dgbsv` sont √©gales aux performances de `dgbtrs` lorsque nous mesurons les temps d'ex√©cutions. 

Cela semble logique √©tant donn√© que `dgbsv` utilise dans son fonctionnement `dgbtrs` et `dgbtrf`, leur complexit√© est donc similaire car un final l'appel √† la r√©solution du syst√®me lin√©aire se fait sur les m√™mes fonctions de BLAS.

## Exercice 6

L'impl√©mentation de la factorisation LU pour les matrices tridiagonales stock√©es en matrices bandes a √©t√© effectu√© comme suit :

```c
int dgbtrftridiag(int *la, int*n, int *kl, int *ku, double *AB, int *lab, int *ipiv, int *info){
  double factor; 
  *info = 0;    
  if (*kl != 1 || *ku != 1) {
    printf("Erreur : La largeur des bandes doit √™tre 1 pour une matrice tridiagonale.\n");
    *info = -1;
    return -1; 
  }
  for (int i = 0; i < *n - 1; i++) {
    if (AB[1 + i * (*lab)] == 0.0) { 
      *info = i + 1; 
      return -1;
    }
    factor = AB[0 + (i + 1) * (*lab)] / AB[1 + i * (*lab)];
    AB[0 + (i + 1) * (*lab)] = factor; 
    AB[1 + (i + 1) * (*lab)] -= factor * AB[2 + i * (*lab)];
  }
  for (int i = 0; i < *n; i++) {
    ipiv[i] = i + 1; 
  }
  return 0; 
}
```

### Analyse de complexit√©

La fonction `dgbtrftridiag` obtient une complexit√© de O(n) gr√¢ce au fait qu'elle utilise des matices bandes et donc qu'il n'y a qu'une boucle for au maximum. 

La complexit√© en esapce est √©galement tr√®s bonne car les matrices bandes n'ont que peu de valeurs nulle; et donc inutiles.

### V√©rification des valeurs

Afin de v√©rifier si notre calcul est correct, il faut commencer par calculer `l'erreur relative`.
Si cette erreur est inf√©rieure √† la limite que nous nous sommes impos√© *(par exemple $>10^{-10})$)*, nous pouvons consid√©rer que les calculs sont corrects.

On peut √©galement valider l'impl√©mentation de `dgbtrftridiag` en multipliant la matrice L et U obtenues apr√®s l'appel √† la fonction. On v√©rifiera alors que le r√©sultat est bien la matrice originale.

# M√©thode de r√©solution It√©rative

## Exercice 7

![convergence_richardson_alpha](convergence_richardsonAlpha.png)

### Convergence

La convergence de l'algorithme de Richardson avec matrices bandes est correcte d√®s la vingtaine d'it√©rations mais converge cependant assez lentement en comparaison d'autres m√©thodes pr√©sent√©es par la suite.

Cette m√©thode obtient une convergence de 10<sup>-3</sup> en 125 it√©rations.

## Exercice 8

![convergence_jacobi](convergence_jacobi.png)

### Convergence

La m√©thode de Jacobi est l'une des plus simple √† impl√©menter. Elle permet une convergence correcte par rapport √† sa complexit√© mais qui est cependant largement d√©pas√©e par Gauss-Seidel.

On peut ici observer une convergence satisfaisante au bout de la vingtaine d'it√©rations avant d'avoir une convergence lente par la suite.

Cette m√©thode obtient √©galement une convergence de 10<sup>-3</sup> en 125 it√©rations.

## Exercice 9

![convergence_gauss_seidel](convergence_gaussSeidel.png)

### Convergence

Gauss-Seidel reste la meilleure impl√©mentation faite en terme de convergence en √©tant ~2 fois plus rapide que les autres ne n√©cessitant qu'une dizaine d'it√©rations avant d'obtenir une convergence convenable.

Cette derni√®re m√©thode obtient une convergence de 10<sup>-3</sup> en 63 it√©rations.